{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import hashlib\n",
    "import google.generativeai as google_genai\n",
    "\n",
    "import google.auth\n",
    "import vertexai\n",
    "import vertexai.generative_models as vertexai_genai\n",
    "import vertexai.language_models as vertexai_plam2\n",
    "from vertexai.generative_models import Content, Part\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google AI Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google_genai.configure(api_key=os.getenv('GOOGLE_API_KEY'), transport='rest')\n",
    "google_genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n",
      "models/embedding-001\n",
      "models/aqa\n"
     ]
    }
   ],
   "source": [
    "for m in google_genai.list_models():\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = google_genai.GenerativeModel('gemini-1.0-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=glm.GenerateContentResponse({'candidates': [{'content': {'parts': [{'text': 'The quick brown fox jumps over the lazy dog.'}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 2, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'token_count': 0, 'grounding_attributions': []}], 'prompt_feedback': {'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'block_reason': 0}}),\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.generate_content(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Gemini Model\n",
    "def setup_gemini_model(\n",
    "    model_name:str,\n",
    "    temperature:float,\n",
    "    max_output_tokens:int,\n",
    "    top_p:float,\n",
    "    top_k:int,\n",
    "    stop_sequence:Optional[List[str]]=None,\n",
    ") -> google_genai.GenerativeModel:\n",
    "    \n",
    "    # Setup Safety Settings\n",
    "    safety_settings = {\n",
    "        # HarmCategory.HARM_CATEGORY_DANGEROUS: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        # HarmCategory.HARM_CATEGORY_DEROGATORY: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        # HarmCategory.HARM_CATEGORY_MEDICAL: HarmBlockThreshold.BLOCK_NONE,\n",
    "        # HarmCategory.HARM_CATEGORY_SEXUAL: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        # HarmCategory.HARM_CATEGORY_TOXICITY: HarmBlockThreshold.BLOCK_NONE,\n",
    "        # HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "        # HarmCategory.HARM_CATEGORY_VIOLENCE: HarmBlockThreshold.BLOCK_NONE,\n",
    "    }\n",
    "    \n",
    "    # Setup Model Config\n",
    "    generation_config = google_genai.GenerationConfig(\n",
    "        candidate_count=1,\n",
    "        stop_sequences=stop_sequence,\n",
    "        max_output_tokens=max_output_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "    )\n",
    "    \n",
    "    # Create a new model\n",
    "    gemini_model = google_genai.GenerativeModel(\n",
    "        model_name=model_name,\n",
    "        safety_settings=safety_settings,\n",
    "        generation_config=generation_config\n",
    "        )\n",
    "\n",
    "    return gemini_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = setup_gemini_model(\n",
    "    model_name='gemini-1.0-pro',\n",
    "    temperature=0,\n",
    "    max_output_tokens=1024,\n",
    "    top_p=1,\n",
    "    top_k=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genai.GenerativeModel(\n",
      "    model_name='models/gemini-1.0-pro',\n",
      "    generation_config={'candidate_count': 1, 'max_output_tokens': 1024, 'temperature': 0, 'top_p': 1, 'top_k': 50},\n",
      "    safety_settings={<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 10>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HARASSMENT: 7>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HATE_SPEECH: 8>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 9>: <HarmBlockThreshold.BLOCK_NONE: 4>},\n",
      "    tools=None,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.count_tokens(\"The quick brown fox jumps over the lazy dog\").total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials, project_id = google.auth.default()\n",
    "LOCATION = os.getenv('GCP_LOCATION')\n",
    "\n",
    "vertexai.init(project=os.getenv('GCP_PROJECT'), location=LOCATION, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Gemini Model\n",
    "def setup_gemini_model(\n",
    "    model_name:str,\n",
    "    temperature:float=0,\n",
    "    max_output_tokens:int=1024,\n",
    "    top_p:float=1,\n",
    "    top_k:int=40,\n",
    "    stop_sequence:Optional[List[str]]=None,\n",
    "    is_vertexai_model:bool=False,\n",
    ") -> Union[google_genai.GenerativeModel, vertexai_genai.GenerativeModel]:\n",
    "    \n",
    "    if is_vertexai_model:\n",
    "        from vertexai.generative_models import GenerativeModel, GenerationConfig, HarmCategory, HarmBlockThreshold\n",
    "    else:\n",
    "        from google.generativeai import GenerativeModel, GenerationConfig\n",
    "        from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "    \n",
    "    # Setup Safety Settings\n",
    "    if is_vertexai_model:\n",
    "        safety_settings = {\n",
    "            # HarmCategory.HARM_CATEGORY_DANGEROUS: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            # HarmCategory.HARM_CATEGORY_DEROGATORY: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            # HarmCategory.HARM_CATEGORY_MEDICAL: HarmBlockThreshold.BLOCK_NONE,\n",
    "            # HarmCategory.HARM_CATEGORY_SEXUAL: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            # HarmCategory.HARM_CATEGORY_TOXICITY: HarmBlockThreshold.BLOCK_NONE,\n",
    "            # HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "            # HarmCategory.HARM_CATEGORY_VIOLENCE: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "    else:\n",
    "        safety_settings = {\n",
    "            # HarmCategory.HARM_CATEGORY_DANGEROUS: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            # HarmCategory.HARM_CATEGORY_DEROGATORY: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "            # HarmCategory.HARM_CATEGORY_MEDICAL: HarmBlockThreshold.BLOCK_NONE,\n",
    "            # HarmCategory.HARM_CATEGORY_SEXUAL: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            # HarmCategory.HARM_CATEGORY_TOXICITY: HarmBlockThreshold.BLOCK_NONE,\n",
    "            # HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "            # HarmCategory.HARM_CATEGORY_VIOLENCE: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "    \n",
    "    # Setup Model Config\n",
    "    generation_config = GenerationConfig(\n",
    "        candidate_count=1,\n",
    "        stop_sequences=stop_sequence,\n",
    "        max_output_tokens=max_output_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "    )\n",
    "    \n",
    "    # Create a new model\n",
    "    gemini_model = GenerativeModel(\n",
    "        model_name=model_name,\n",
    "        safety_settings=safety_settings,\n",
    "        generation_config=generation_config\n",
    "        )\n",
    "\n",
    "    return gemini_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TextBison Model in VertexAI\n",
    "def setup_plam2_model(\n",
    "    model_name:str,\n",
    "    temperature:float=0,\n",
    "    max_output_tokens:int=1024,\n",
    "    top_p:float=1,\n",
    "    top_k:int=40,\n",
    "    stop_sequences:Optional[List[str]]=None,\n",
    ") -> Tuple[vertexai_plam2.TextGenerationModel, dict]:\n",
    "    \n",
    "    if \"@002\" in model_name:\n",
    "        max_output_tokens = min(max_output_tokens, 1024)\n",
    "    top_k = min(top_k, 40)\n",
    "    \n",
    "    # Load the Model\n",
    "    palm2_model = vertexai_plam2.TextGenerationModel.from_pretrained(model_name)\n",
    "    \n",
    "    # Set Parameters\n",
    "    parameters = {\n",
    "        'temperature': temperature,\n",
    "        'max_output_tokens': max_output_tokens,\n",
    "        'top_p': top_p,\n",
    "        'top_k': top_k,\n",
    "        'stop_sequences': stop_sequences,\n",
    "    }\n",
    "    \n",
    "    return palm2_model, parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model = setup_gemini_model('gemini-1.0-pro', is_vertexai_model=False)\n",
    "gemini_vertexai_model = setup_gemini_model('gemini-1.0-pro-001', is_vertexai_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model_output = gemini_model.generate_content(\"The quick brown fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_vertexai_model_output = gemini_vertexai_model.generate_content(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The quick brown fox jumps over the lazy dog.', 9, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_vertexai_model_output.text, gemini_vertexai_model_output.to_dict()['usage_metadata']['prompt_token_count'], gemini_vertexai_model_output.to_dict()['usage_metadata']['candidates_token_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bison_model, parameters = setup_plam2_model('text-bison')\n",
    "text_bison_002_model, parameters = setup_plam2_model('text-bison@002')\n",
    "text_bison_32k_model, parameters = setup_plam2_model('text-bison-32k')\n",
    "text_bison_32k_002_model, parameters = setup_plam2_model('text-bison-32k@002')\n",
    "text_unicorn_001_model, parameters = setup_plam2_model('text-unicorn@001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " The quick brown fox jumps over the lazy dog is a pangram, which means that it contains all of the letters of the alphabet. It is often used as a test phrase for typewriters and computers."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bison_model.predict(\"The quick brown fox jumps over the lazy dog\", **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " The quick brown fox jumps over the lazy dog is a pangram, which means that it contains all of the letters of the alphabet. It is often used as a test phrase for typewriters and computers."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bison_002_model.predict(\"The quick brown fox jumps over the lazy dog\", **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " The quick brown fox jumps over the lazy dog is a pangram, which is a sentence that contains all of the letters of the alphabet at least once. This particular pangram is often used to test typewriters and printers, as it ensures that all of the keys are working properly."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bison_32k_model.predict(\"The quick brown fox jumps over the lazy dog\", **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The quick brown fox jumps over the lazy dog is a pangram, which is a sentence that contains all of the letters of the alphabet at least once. This particular pangram is often used to test typewriters and printers, as it ensures that all of the keys are working properly.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bison_32k_002_model.predict(\"The quick brown fox jumps over the lazy dog\", **parameters).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The quick brown fox jumps over the lazy dog is a pangram, which means it contains every letter of the alphabet. It is often used to test typewriters and keyboards.\n",
       "\n",
       "The sentence is also a holoalphabetic sentence, which means it contains every letter of the alphabet in alphabetical order.\n",
       "\n",
       "The sentence is believed to have originated in the 19th century. It was first published in The Boston Journal in 1885.\n",
       "\n",
       "The sentence has been used in a variety of contexts, including in advertising, literature, and music.\n",
       "\n",
       "In advertising, the sentence has been used to promote products such as typewriters, keyboards, and printers.\n",
       "\n",
       "In literature, the sentence has been used in a variety of works, including novels, short stories, and poems.\n",
       "\n",
       "In music, the sentence has been used in a variety of songs, including \"The Quick Brown Fox\" by The Beach Boys and \"The Lazy Dog\" by The Grateful Dead.\n",
       "\n",
       "The sentence is a popular example of a pangram and a holoalphabetic sentence. It is a fun and challenging sentence to type, and it is a great way to test your typing skills."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_unicorn_001_model.predict(\"The quick brown fox jumps over the lazy dog\", **parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"You are a \"Public Insurance\" Underwriter, researching about the insurance risk liabilities and pro-active risk mitigation work done by or associated with given public entity - {{ insured }}. \n",
    "\n",
    "Your task is to analysize the given news article for insurance risk liabilities and pro-active risk mitigation for each of the mentioned \"Line of Business\" (LOB).\n",
    "\n",
    "<LIST_OF_LOBs>\n",
    "General Liability: Liability or pro-active measures for events related to Bodily injury from slips, trips, falls, election irregularities, theft, fraud, misappropriation, faulty design, data breaches, sewer back-ups, except Automobile and professional liability.\n",
    "Employment Practices Liability: Liability or pro-active measures for events/claims related to discrimination, wrongful termination, sexual harassment, retaliation, misconduct, federal act violations and other employment-process-related allegations.\n",
    "Law Enforcement Liability: Liability or pro-active measures for events/claims related to wrongful death or imprisonment, civil rights violations, false arrest, excessive force, suicides/deaths in custody, misconduct, excessive force, profiling, shootings, illegal police activities, law enforcement pursuit/chase, personal injury or property damage caused by a wrongful act committed by or on behalf of a public entity while conducting law enforcement activities or operations.\n",
    "Property Liability: Liability or pro-active measures for events/claims related to weather damage, potential for extreme weather, property damage, disrepair, abandoned or vacant, solar panels, buildings, contents, equipment, and other property owned by the public entity.\n",
    "Auto Liability: Liability or pro-active measures for events/claims related to vehicular crashes/accidents, law enforcement pursuit/chase, commercial auto and commercial general liability exposure of any land motor vehicle, trailer or semi-trailer for travel on public road. Does not include \"mobile equipment\".\n",
    "Employee Benefits Liability: Liability or pro-active measures for events/claims related to retirements, retirement savings, healthcare costs, benefits, errors or omissions in the administration of employee benefit programs.\n",
    "Zoning Liability: Liability or pro-active measures for events/claims related to land use, ordinance, code, etc. violations, lawsuits and/or disputes.\n",
    "Liquor Liability: Liability or pro-active measures for events/claims related to Liquor compliance, licensing, code issues and/or licenses obtained or plans to serve liquor to the community/host events.\n",
    "Dam Liability: Liability or pro-active measures for events/claims related to damages, breaches and/or inspections, water supply hinderance, etc. of dams, lapses in the dam's maintenance and inspection protocols.\n",
    "Inland Marine Liability: Liability or pro-active measures for events/claims related to loss, damage and/or theft of equipment, machinery, products, or other property at a job site, store at a warehouse, or transported over land by train or truck.\n",
    "Boiler Liability: Liability or pro-active measures for events/claims related to Power outages and surges due to mechanical failure, frozen pipes, and/or severe weather impacting boiler and machinery.\n",
    "</LIST_OF_LOBs>\n",
    "\n",
    "The analysis has to be done in a step-by-step manner.\n",
    "Follow all the given steps to complete the task and output result of each step in requested format.\n",
    "\n",
    "STEPS:\n",
    "Step 1:\n",
    "Check if the article talks about the concerned public entity - {{ insured }} or individuals related to this public entity and not about any other individuals or any other private entity.\n",
    "If the article is not about the concerned public entity - {{ insured }}, then the analysis is not required and but do complete the next steps.\n",
    "\n",
    "Step 2:\n",
    "Read the complete article as an underwriter scrutinizing the public entity - {{ insured }}.\n",
    "List out all the LOBs relevant (if any) to the events mentioned involving the public entity - {{ insured }}.\n",
    "The LOBs to be considered should be only from the above-given list of 11 LOBs \n",
    "[General Liability, Employment Practices Liability, Law Enforcement Liability, Property Liability, Auto Liability, Employee Benefits Liability, Zoning Liability, Dam Liability, Inland Marine Liability, Boiler Liability].\n",
    "\n",
    "Step 3:\n",
    "For each of the LOBs mentioned in Step 2, identify the reasons given in the article for insurance liability exposure and/or steps taken for proactive risk mitigation. \n",
    "The output has to be in JSON format, enclosed in <LOB_CLASSIFICATION></LOB_CLASSIFICATION> XML tags.\n",
    "Use these exact tags, nothing else. Return \"{}\" in tags if no LOB is identified in Step 2.\n",
    "Example:\n",
    "<LOB_CLASSIFICATION>\n",
    "{\n",
    "    LOB1 | STRING - Name of LOB: {\n",
    "        \"detailed_reasoning\": STRING | Why does the article invokes this particular insurance liability exposure and/or steps taken for proactive risk mitigation. The reasoning should be based on actual incidents mentioned in the article and not what would have happened or can happen,\n",
    "        \"identified\": BOOLEAN - Whether LOB risk or risk-mitigation is actually identified,\n",
    "    },\n",
    "    LOB2 : {\n",
    "        \"detailed_reasoning\": STRING,\n",
    "        \"identified\": BOOLEAN,\n",
    "    }\n",
    "}\n",
    "</LOB_CLASSIFICATION>\n",
    "\n",
    "<ARTICLE>\n",
    "{{ article }}\n",
    "<\\ARTICLE>\n",
    "\n",
    "OUTPUT:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "insured = \"TOWN OF MCCORDSVILLE, HANCOCK COUNTY, INDIANA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"HANCOCK COUNTY — A few weeks into the new year, officials with the Hancock County Sheriff’s Department (HCSD) shared run statistics from 2023 and compared them with numbers from 2022 as well as from 2021.\n",
    "\n",
    "Captain Robert Harris, public information officer for the Sheriff’s office, said the statistic show 2023 was a busy year for the department, with huge numbers across the board starting with approximately 25,707 total patrol events.\n",
    "\n",
    "The patrol event numbers from 2023 are up from 2022 when they had 23,956 patrol events, and they’re even higher than the ones recorded in 2021 when they had 24,138 events.\n",
    "\n",
    "“I believe this is due to growth of new business, residents and commuters in Hancock County,” Harris said.\n",
    "\n",
    "Sheriff’s officials are on record saying the creation of many large warehouse businesses on the west side of the county kept them moving in 2023 with numerous calls per day.\n",
    "\n",
    "Growth throughout the county could explain why HCSD field arrests were also up with 730 field arrests in 2023. That’s several hundred more than in 2022 when there were only 521 field arrests compared with only 447 field arrests in 2021.\n",
    "\n",
    "More growth means more vehicles on county roads, and that means the number of traffic stops in 2023 increased by over 1,400 to 5,061 compared to 2022 numbers when there were only 3,916 traffic stops and 3,016 traffic stops in 2021.\n",
    "\n",
    "Sheriff’s officials also spend time each year handling situations that end up being civil events. In 2023, they had 2,137 civil runs compared with 1,987 civil runs in 2022. There were 1,803 in 2021.\n",
    "\n",
    "When it came to incident reports, case reports to investigations, numbers were up there as well. There were 1,466 reports in 2023, up nearly 100 from 2022 when there were 1,351 reports to investigations. Still, the highest incidents for reports to investigation occurred in 2021 when there where 1,515.\n",
    "\n",
    "The HCSD also keeps track of happenings at the Hancock County Jail. Harris noted jail bookings were also up, but just slightly in 2023. Last year, 2,192 inmates were booked into the new jail. That number is up by only 20 inmates compared to 2022 numbers when 2,172 inmates were booked into the jail. Both years though are way up from 2021 when the new jail wasn’t yet open and only 1,246 people were taken into custody.\n",
    "\n",
    "Jail release numbers show while many are taken into custody, there are also high turnover numbers. The jail released 2,160 inmates in 2023, up slightly from 2022 when they released 2,090 inmates. Release could include transferring inmates to the Indiana Department of Corrections; another county jail, probation or outright release. Jail releases were 1,197 in 2021.\n",
    "\n",
    "While the report numbers are up pretty much across the board for Sheriff’s officials, Harris noted the force is doing as best it can to keep up with the higher demands for public service and officials feel like the volume of work will continue to increase in the coming years.\n",
    "\n",
    "“I feel we will continue to see increased numbers as the county grows,” Harris said.\n",
    "\n",
    "With the growth, officials at the Sheriff’s office note they will do all they can to continue to patrol and monitor the county as best they can, but with so much growth they’re going to have to hire more deputies both for patrol and at the jail.\n",
    "\n",
    "“We would still like to add more deputies on the streets and more employees to expand programs,” Harris said.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [Content(\n",
    "    role=\"user\",\n",
    "    parts=[\n",
    "        Part.from_text(f'''You are a \"Public Insurance\" Underwriter, researching about the insurance risk liabilities and pro-active risk mitigation work done by or associated with given public entity - { insured }.\n",
    "The analysis has to be done in a step-by-step manner.\n",
    "Follow all the given steps to complete the task and output result of each step in requested format.'''),\n",
    "        Part.from_text(f'''<ARTICLE>\n",
    "{ article }\n",
    "<\\ARTICLE>'''),\n",
    "        Part.from_text(f'''Step 1:\n",
    "Check if the article talks about the concerned public entity - { insured } or individuals related to this public entity and not about any other individuals or any other private entity.\n",
    "If the article is not about the concerned public entity - { insured }, then the analysis is not required and but do complete the next steps.\n",
    "'''),\n",
    "    ]\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = Content(\n",
    "    role=\"user\",\n",
    "    parts=[\n",
    "        Part.from_text(f'''You are a \"Public Insurance\" Underwriter, researching about the insurance risk liabilities and pro-active risk mitigation work done by or associated with given public entity - { insured }.\n",
    "The analysis has to be done in a step-by-step manner.\n",
    "Follow all the given steps to complete the task and output result of each step in requested format.'''),\n",
    "        Part.from_text(f'''<ARTICLE>\n",
    "{ article }\n",
    "<\\ARTICLE>'''),\n",
    "        Part.from_text(f'''Step 1:\n",
    "Check if the article talks about the concerned public entity - { insured } or individuals related to this public entity and not about any other individuals or any other private entity.\n",
    "If the article is not about the concerned public entity - { insured }, then the analysis is not required and but do complete the next steps.\n",
    "'''),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = gemini_vertexai_model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(input_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"The article is about the Hancock County Sheriff\\'s Department (HCSD), which is a public entity in Hancock County, Indiana. The article does not mention the Town of McCordsville, Hancock County, Indiana. Therefore, the analysis is not required.\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 1065\n",
       "  candidates_token_count: 51\n",
       "  total_token_count: 1116\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(f\"\"\"Step 2:\n",
    "Read the complete article as an underwriter scrutinizing the public entity - { insured }.\n",
    "List out all the LOBs relevant (if any) to the events mentioned involving the public entity - { insured }.\n",
    "The LOBs to be considered should be only from the above-given list of 11 LOBs \n",
    "[General Liability, Employment Practices Liability, Law Enforcement Liability, Property Liability, Auto Liability, Employee Benefits Liability, Zoning Liability, Dam Liability, Inland Marine Liability, Boiler Liability].\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"The article does not mention the Town of McCordsville, Hancock County, Indiana. Therefore, I cannot list out the LOBs relevant to the events mentioned involving the public entity - TOWN OF MCCORDSVILLE, HANCOCK COUNTY, INDIANA.\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 1242\n",
       "  candidates_token_count: 49\n",
       "  total_token_count: 1291\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\"\"\"Step 3:\n",
    "For each of the LOBs mentioned in Step 2, identify the reasons given in the article for insurance liability exposure and/or steps taken for proactive risk mitigation. \n",
    "The output has to be in JSON format, enclosed in <LOB_CLASSIFICATION></LOB_CLASSIFICATION> XML tags.\n",
    "Use these exact tags, nothing else. Return \"<LOB_CLASSIFICATION>{}</LOB_CLASSIFICATION>\" in tags if no LOB is identified in Step 2.\n",
    "Example:\n",
    "<LOB_CLASSIFICATION>\n",
    "{\n",
    "    LOB1 | STRING - Name of LOB: {\n",
    "        \"detailed_reasoning\": STRING | Why does the article invokes this particular insurance liability exposure and/or steps taken for proactive risk mitigation. The reasoning should be based on actual incidents mentioned in the article and not what would have happened or can happen,\n",
    "        \"identified\": BOOLEAN - Whether LOB risk or risk-mitigation is actually identified,\n",
    "    },\n",
    "    LOB2 : {\n",
    "        \"detailed_reasoning\": STRING,\n",
    "        \"identified\": BOOLEAN,\n",
    "    }\n",
    "}\n",
    "</LOB_CLASSIFICATION>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"<LOB_CLASSIFICATION>{}</LOB_CLASSIFICATION>\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 1747\n",
       "  candidates_token_count: 13\n",
       "  total_token_count: 1760\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The analysis has to be done in a step-by-step manner.\n",
    "Follow all the given steps to complete the task and output result of each step in requested format.\n",
    "\n",
    "\n",
    "\n",
    "<ARTICLE>\n",
    "{{ article }}\n",
    "<\\ARTICLE>\n",
    "\n",
    "\n",
    "for insurance risk liabilities and pro-active risk mitigation for each of the mentioned \"Line of Business\" (LOB).\n",
    "\n",
    "\n",
    "Your task is to analysize the given news article for insurance risk liabilities and pro-active risk mitigation for each of the mentioned \"Line of Business\" (LOB).\n",
    "\n",
    "<LIST_OF_LOBs>\n",
    "General Liability: Liability or pro-active measures for events related to Bodily injury from slips, trips, falls, election irregularities, theft, fraud, misappropriation, faulty design, data breaches, sewer back-ups, except Automobile and professional liability.\n",
    "Employment Practices Liability: Liability or pro-active measures for events/claims related to discrimination, wrongful termination, sexual harassment, retaliation, misconduct, federal act violations and other employment-process-related allegations.\n",
    "Law Enforcement Liability: Liability or pro-active measures for events/claims related to wrongful death or imprisonment, civil rights violations, false arrest, excessive force, suicides/deaths in custody, misconduct, excessive force, profiling, shootings, illegal police activities, law enforcement pursuit/chase, personal injury or property damage caused by a wrongful act committed by or on behalf of a public entity while conducting law enforcement activities or operations.\n",
    "Property Liability: Liability or pro-active measures for events/claims related to weather damage, potential for extreme weather, property damage, disrepair, abandoned or vacant, solar panels, buildings, contents, equipment, and other property owned by the public entity.\n",
    "Auto Liability: Liability or pro-active measures for events/claims related to vehicular crashes/accidents, law enforcement pursuit/chase, commercial auto and commercial general liability exposure of any land motor vehicle, trailer or semi-trailer for travel on public road. Does not include \"mobile equipment\".\n",
    "Employee Benefits Liability: Liability or pro-active measures for events/claims related to retirements, retirement savings, healthcare costs, benefits, errors or omissions in the administration of employee benefit programs.\n",
    "Zoning Liability: Liability or pro-active measures for events/claims related to land use, ordinance, code, etc. violations, lawsuits and/or disputes.\n",
    "Liquor Liability: Liability or pro-active measures for events/claims related to Liquor compliance, licensing, code issues and/or licenses obtained or plans to serve liquor to the community/host events.\n",
    "Dam Liability: Liability or pro-active measures for events/claims related to damages, breaches and/or inspections, water supply hinderance, etc. of dams, lapses in the dam's maintenance and inspection protocols.\n",
    "Inland Marine Liability: Liability or pro-active measures for events/claims related to loss, damage and/or theft of equipment, machinery, products, or other property at a job site, store at a warehouse, or transported over land by train or truck.\n",
    "Boiler Liability: Liability or pro-active measures for events/claims related to Power outages and surges due to mechanical failure, frozen pipes, and/or severe weather impacting boiler and machinery.\n",
    "</LIST_OF_LOBs>\n",
    "\n",
    "\n",
    "The output has to be in JSON format, enclosed in <LOB_CLASSIFICATION></LOB_CLASSIFICATION> XML tags.\n",
    "Use these exact tags, nothing else. Return <LOB_CLASSIFICATION>{}</LOB_CLASSIFICATION> in tags if no LOB is identified in Step 2.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
